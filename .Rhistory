# library(clusterSim)
# stm<-shapes.two.moon(360)
# plot(stm$data,col=rainbow(3)[stm$clusters])
#
# library(e1071)
#
# model = svm(stm$clusters ~ stm$data)
#
# predictedY= predict(model, stm$data)
#
# points(predictedY, col = "blue", pch=4)
#
# error = stm$clusters - predictedY
# svrPredictionRMSE = mean(error**2)  # 3.157061
# svrPredictionRMSE
#
#
# #### K(Xi, Xj ) = e^−||Xi−Xj ||^2/2σ2
#
# # Parameters:
# # SVM-Type:  eps-regression
# # SVM-Kernel:  radial
# # cost:  1
# # gamma:  0.5
# # epsilon:  0.1
#
# library(kernlab)
#
# rbf <- rbfdot(sigma = 0.5)
# rbf
# kpar(rbf)
#
# K <- rbf(stm$data[,1], stm$data[,2])
# K
# ?ksvm
#
# mdo = ksvm(stm$data, kernel = rbfdot)
# ####
#
# x_1 = stm$data[,1]
# x_2 = stm$data[,2]
#
# fullvect = append(x_1,x_2)
#
#
# Z_x = array()
# sigma = 2
#
# library(pracma)
# library(rdist)
# D = (pdist(stm$data,metric = "euclidean"))
#
# D = exp(-(D*D)/ ( 2*sigma**2));
# z = x_1*x_2^2
#
#
# source('./oen_minkowski.R')
#
# for(x1 in fullvect){
#   sum = 0
#   for(x2 in fullvect){
#     sum = sum + exp(-(minkowsky(x1,x2,2)**2)/(2*sigma**2))
#   }
#   Z_x = append(Z_x, sum)#/length(fullvect)
# }
#
# Z_x= Z_x[-1] #remove the NAN
# #### K(Xi, Xj ) = e^−||Xi−Xj ||^2/2σ2
#
# dat = Z_x[1:720]+Z_x[721:1440]
#
# library(rgl)
# plot3d(x_1, x_2, (x_1**1 + x_2**2), col = stm$clusters)
#
#
# #########################
#
# dataset = stm$data
# dataset = cbind(dataset, stm$clusters)
# library(e1071)
# https://www.dcode.fr/lagrange-interpolating-polynomial
# picked 4 random points
z = -1.37845*x_2**3 - 2.11278*x_2**2 + 0.0656642*x_2 + 0.2 - x_1
y = function(x_2)(-1.37845*x_2**3 - 2.11278*x_2**2 + 0.0656642*x_2 + 0.2)
curve(y, from=-3, to=2, ylim=c(-1.5,1))
points(x_2, x_1, col=stm$clusters)
library(rgl)
plot3d(x_2, x_1, z, col = stm$clusters)
planes3d(0,0,1, alpha=0.5)
library(clusterSim)
stm<-shapes.two.moon(360)
plot(stm$data,col=rainbow(3)[stm$clusters])
x_1 = stm$data[,1]
x_2 = stm$data[,2]
source("G:/My Drive/1. EIT Digital master/Estland/Semester 1/Data mining/data-mining-iti8730-hw2/kernel-trick.R", encoding = 'UTF-8')
dataset[,1]
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset[,1]
sin(dataset[,1])
log2(dataset[,1])
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,sin(dataset[,1]))
dataset=cbind(dataset,cos(dataset[,3]))
dataset=cbind(dataset,exp(dataset[,4]))
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,sin(dataset[,1]))
dataset=cbind(dataset,cos(dataset[,3]))
dataset=cbind(dataset,exp(dataset[,4]))
library(stats)
pc <- prcomp(dataset,
center = TRUE,
scale. = TRUE)
summary(pc)
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,sin(dataset[,1]))
dataset=cbind(dataset,cos(dataset[,1]))
dataset=cbind(dataset,exp(dataset[,1]))
library(stats)
pc <- prcomp(dataset,
center = TRUE,
scale. = TRUE)
summary(pc)
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]*sin(dataset[,1]))
dataset=cbind(dataset,dataset[,1]*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,1]*exp(dataset[,1]))
library(stats)
pc <- prcomp(dataset,
center = TRUE,
scale. = TRUE)
summary(pc)
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]*sin(dataset[,1]))
dataset=cbind(dataset,dataset[,1]*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,1]*tanh(dataset[,1]))
library(stats)
pc <- prcomp(dataset,
center = TRUE,
scale. = TRUE)
summary(pc)
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]*sin(dataset[,1]))
dataset=cbind(dataset,dataset[,1]*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,1]*tanh(dataset[,2]))
library(stats)
pc <- prcomp(dataset,
center = TRUE,
scale. = TRUE)
summary(pc)
rm(list=ls())
#
# library(e1071)
#
# model = svm(stm$clusters ~ stm$data)
#
# predictedY= predict(model, stm$data)
#
# points(predictedY, col = "blue", pch=4)
#
# error = stm$clusters - predictedY
# svrPredictionRMSE = mean(error**2)  # 3.157061
# svrPredictionRMSE
#
#
# #### K(Xi, Xj ) = e^−||Xi−Xj ||^2/2σ2
#
# # Parameters:
# # SVM-Type:  eps-regression
# # SVM-Kernel:  radial
# # cost:  1
# # gamma:  0.5
# # epsilon:  0.1
#
# library(kernlab)
#
# rbf <- rbfdot(sigma = 0.5)
# rbf
# kpar(rbf)
#
# K <- rbf(stm$data[,1], stm$data[,2])
# K
# ?ksvm
#
# mdo = ksvm(stm$data, kernel = rbfdot)
# ####
#
# x_1 = stm$data[,1]
# x_2 = stm$data[,2]
#
# fullvect = append(x_1,x_2)
#
#
# Z_x = array()
# sigma = 2
#
# library(pracma)
# library(rdist)
# D = (pdist(stm$data,metric = "euclidean"))
#
# D = exp(-(D*D)/ ( 2*sigma**2));
# z = x_1*x_2^2
#
#
# source('./oen_minkowski.R')
#
# for(x1 in fullvect){
#   sum = 0
#   for(x2 in fullvect){
#     sum = sum + exp(-(minkowsky(x1,x2,2)**2)/(2*sigma**2))
#   }
#   Z_x = append(Z_x, sum)#/length(fullvect)
# }
#
# Z_x= Z_x[-1] #remove the NAN
# #### K(Xi, Xj ) = e^−||Xi−Xj ||^2/2σ2
#
# dat = Z_x[1:720]+Z_x[721:1440]
#
# library(rgl)
# plot3d(x_1, x_2, (x_1**1 + x_2**2), col = stm$clusters)
#
#
# #########################
#
# dataset = stm$data
# dataset = cbind(dataset, stm$clusters)
# library(e1071)
library(clusterSim)
stm<-shapes.two.moon(360)
x11()
plot(stm$data,col=rainbow(3)[stm$clusters])
x_1 = stm$data[,1]
x_2 = stm$data[,2]
# https://www.dcode.fr/lagrange-interpolating-polynomial
# picked 4 random points
z = -1.37845*x_2**3 - 2.11278*x_2**2 + 0.0656642*x_2 + 0.2 - x_1
y = function(x_2)(-1.37845*x_2**3 - 2.11278*x_2**2 + 0.0656642*x_2 + 0.2)
x11()
curve(y, from=-3, to=2, ylim=c(-1.5,1))
points(x_2, x_1, col=stm$clusters)
library(rgl)
plot3d(x_2, x_1, z, col = stm$clusters)
planes3d(0,0,1, alpha=0.5)
#to-do: make kernel from polynomial
rm(list=ls())
source("G:/My Drive/1. EIT Digital master/Estland/Semester 1/Data mining/collectivestrength.R")
View(Groceries)
# Create an item frequency plot for the top 20 items
itemFrequencyPlot(Groceries,topN=20,type="absolute")
# Create an item frequency plot for the top 20 items
x11()
source("G:/My Drive/1. EIT Digital master/Estland/Semester 1/Data mining/collectivestrength.R")
View(Groceries)
View(Groceries)
inspect(rules[1:5])
# this is demo script for text data mining
#
# clear everything
rm(list=ls())
### Data exploration and preprocessing
### Omar El Nahhas
rm(list=ls())
set.seed(1337)
packages_used = c("rstudioapi",
"arules",
"dplyr")
for(package in packages_used){
if(package %in% rownames(installed.packages()) == FALSE) {
install.packages(package)
}
}
setwd_current_path = function(){
library(rstudioapi)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd('..')
print(getwd())
}
setwd_current_path()
library(arules)
library(dplyr)
######### BEGIN LOAD DATA
athletes_data = read.csv("./Data/athletes.csv", header=T, as.is=T)
events_data = read.csv("./Data/events.csv", header=T, as.is=T)
######### END LOAD DATA
### To-do:
# Determine the goals - why is this data analysed?
# Remove unused variables (id, name, nationality?)
# Discretize the ages
# Remove/impute samples without height/weight
# Make a function which easily filters the dataset by wished for search queries
### Goals:
# find relations between an athlete's background, physical properties and their success in the sport
# find relationships between sports: are some sports f.e. More skill based or more physical based?
### Remove unused variables
athletes_data <- subset(athletes_data, select = -c(id, name, info))
### Transform variables to factors
athletes_data$nationality = factor(athletes_data$nationality)
athletes_data$sex = factor(athletes_data$sex)
athletes_data$sport = factor(athletes_data$sport)
### Discretization of variables
## Age
current_year = 2022
athletes_data$date_of_birth = current_year - strtoi(substr(athletes_data$date_of_birth, 1, 4))
min(athletes_data$date_of_birth)
max(athletes_data$date_of_birth)
mean((athletes_data$date_of_birth))
hist(athletes_data$date_of_birth)
athletes_data$date_of_birth = cut(athletes_data$date_of_birth, c(15,20, 25, 30, 35, 40, 45, 50, 55, 60, 65,70))
#rename to age instead of date of birth
athletes_data = dplyr::rename(athletes_data, age = date_of_birth)
## Height
# tall for male and female have different meanings, and are therefore labelled
# relative to the same gender. So 1.80 for male is considered average, but for a
# female 1.80 is considered tall.
hist(athletes_data$height)
hist(athletes_data$height[athletes_data$sex == 'female'])
hist(athletes_data$height[athletes_data$sex == 'male'])
summary(athletes_data$height)
athletes_data$height = cut(athletes_data$height, c(1.20,1.30,1.40, 1.50, 1.60, 1.70, 1.80, 1.90, 2.00, 2.10, 2.20))
# athletes_data$height[athletes_data$sex == 'female'] = arules::discretize(athletes_data$height[athletes_data$sex == 'female'], method = "cluster",labels = c('short_f', 'average_f', 'tall_f'))
# athletes_data$height[athletes_data$sex == 'male'] = arules::discretize(athletes_data$height[athletes_data$sex == 'male'], method = "cluster",labels = c('short_m', 'average_m', 'tall_m'))
#
# athletes_data$height = factor(athletes_data$height, levels = c(1, 2, 3), labels = c('short', 'average', 'tall'))
## Weight
# heavy for male and female have different meanings, and are therefore labelled
# relative to the same gender. So 80kg for male is considered average, but for a
# female 80kg is considered heavy
hist(athletes_data$weight)
hist(athletes_data$weight[athletes_data$sex == 'female'])
hist(athletes_data$weight[athletes_data$sex == 'male'])
summary(athletes_data$weight)
athletes_data$weight = cut(athletes_data$weight, c(30,40,50,60, 70, 80, 90, 100, 110, 120, 170))
table(athletes_data$weight)
### Data exploration and preprocessing
### Omar El Nahhas
rm(list=ls())
set.seed(1337)
packages_used = c("rstudioapi",
"arules",
"dplyr")
for(package in packages_used){
if(package %in% rownames(installed.packages()) == FALSE) {
install.packages(package)
}
}
setwd_current_path = function(){
library(rstudioapi)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd('..')
print(getwd())
}
setwd_current_path()
library(arules)
library(dplyr)
######### BEGIN LOAD DATA
athletes_data = read.csv("./Data/athletes.csv", header=T, as.is=T)
events_data = read.csv("./Data/events.csv", header=T, as.is=T)
######### END LOAD DATA
### To-do:
# Determine the goals - why is this data analysed?
# Remove unused variables (id, name, nationality?)
# Discretize the ages
# Remove/impute samples without height/weight
# Make a function which easily filters the dataset by wished for search queries
### Goals:
# find relations between an athlete's background, physical properties and their success in the sport
# find relationships between sports: are some sports f.e. More skill based or more physical based?
### Remove unused variables
athletes_data <- subset(athletes_data, select = -c(id, name, info))
### Transform variables to factors
athletes_data$nationality = factor(athletes_data$nationality)
athletes_data$sex = factor(athletes_data$sex)
athletes_data$sport = factor(athletes_data$sport)
### Discretization of variables
## Age
current_year = 2022
athletes_data$date_of_birth = current_year - strtoi(substr(athletes_data$date_of_birth, 1, 4))
min(athletes_data$date_of_birth)
max(athletes_data$date_of_birth)
mean((athletes_data$date_of_birth))
hist(athletes_data$date_of_birth)
athletes_data$date_of_birth = cut(athletes_data$date_of_birth, c(15,20, 25, 30, 35, 40, 45, 50, 55, 60, 65,70))
#rename to age instead of date of birth
athletes_data = dplyr::rename(athletes_data, age = date_of_birth)
## Height
# tall for male and female have different meanings, and are therefore labelled
# relative to the same gender. So 1.80 for male is considered average, but for a
# female 1.80 is considered tall.
hist(athletes_data$height)
hist(athletes_data$height[athletes_data$sex == 'female'])
hist(athletes_data$height[athletes_data$sex == 'male'])
summary(athletes_data$height)
athletes_data$height = cut(athletes_data$height, c(1.20,1.30,1.40, 1.50, 1.60, 1.70, 1.80, 1.90, 2.00, 2.10, 2.20))
# athletes_data$height[athletes_data$sex == 'female'] = arules::discretize(athletes_data$height[athletes_data$sex == 'female'], method = "cluster",labels = c('short_f', 'average_f', 'tall_f'))
# athletes_data$height[athletes_data$sex == 'male'] = arules::discretize(athletes_data$height[athletes_data$sex == 'male'], method = "cluster",labels = c('short_m', 'average_m', 'tall_m'))
#
# athletes_data$height = factor(athletes_data$height, levels = c(1, 2, 3), labels = c('short', 'average', 'tall'))
## Weight
# heavy for male and female have different meanings, and are therefore labelled
# relative to the same gender. So 80kg for male is considered average, but for a
# female 80kg is considered heavy
hist(athletes_data$weight)
hist(athletes_data$weight[athletes_data$sex == 'female'])
hist(athletes_data$weight[athletes_data$sex == 'male'])
summary(athletes_data$weight)
athletes_data$weight = cut(athletes_data$weight, c(30,40,50,60, 70, 80, 90, 100, 110, 120, 130, 170))
table(athletes_data$weight)
### Data exploration and preprocessing
### Omar El Nahhas
rm(list=ls())
set.seed(1337)
packages_used = c("rstudioapi",
"arules",
"dplyr")
for(package in packages_used){
if(package %in% rownames(installed.packages()) == FALSE) {
install.packages(package)
}
}
setwd_current_path = function(){
library(rstudioapi)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd('..')
print(getwd())
}
setwd_current_path()
library(arules)
library(dplyr)
######### BEGIN LOAD DATA
athletes_data = read.csv("./Data/athletes.csv", header=T, as.is=T)
events_data = read.csv("./Data/events.csv", header=T, as.is=T)
######### END LOAD DATA
### To-do:
# Determine the goals - why is this data analysed?
# Remove unused variables (id, name, nationality?)
# Discretize the ages
# Remove/impute samples without height/weight
# Make a function which easily filters the dataset by wished for search queries
### Goals:
# find relations between an athlete's background, physical properties and their success in the sport
# find relationships between sports: are some sports f.e. More skill based or more physical based?
### Remove unused variables
athletes_data <- subset(athletes_data, select = -c(id, name, info))
### Transform variables to factors
athletes_data$nationality = factor(athletes_data$nationality)
athletes_data$sex = factor(athletes_data$sex)
athletes_data$sport = factor(athletes_data$sport)
### Discretization of variables
## Age
current_year = 2022
athletes_data$date_of_birth = current_year - strtoi(substr(athletes_data$date_of_birth, 1, 4))
min(athletes_data$date_of_birth)
max(athletes_data$date_of_birth)
mean((athletes_data$date_of_birth))
hist(athletes_data$date_of_birth)
athletes_data$date_of_birth = cut(athletes_data$date_of_birth, c(15,20, 25, 30, 35, 40, 45, 50, 55, 60, 65,70))
#rename to age instead of date of birth
athletes_data = dplyr::rename(athletes_data, age = date_of_birth)
## Height
# tall for male and female have different meanings, and are therefore labelled
# relative to the same gender. So 1.80 for male is considered average, but for a
# female 1.80 is considered tall.
hist(athletes_data$height)
hist(athletes_data$height[athletes_data$sex == 'female'])
hist(athletes_data$height[athletes_data$sex == 'male'])
summary(athletes_data$height)
athletes_data$height = cut(athletes_data$height, c(1.20,1.30,1.40, 1.50, 1.60, 1.70, 1.80, 1.90, 2.00, 2.10, 2.20))
# athletes_data$height[athletes_data$sex == 'female'] = arules::discretize(athletes_data$height[athletes_data$sex == 'female'], method = "cluster",labels = c('short_f', 'average_f', 'tall_f'))
# athletes_data$height[athletes_data$sex == 'male'] = arules::discretize(athletes_data$height[athletes_data$sex == 'male'], method = "cluster",labels = c('short_m', 'average_m', 'tall_m'))
#
# athletes_data$height = factor(athletes_data$height, levels = c(1, 2, 3), labels = c('short', 'average', 'tall'))
## Weight
# heavy for male and female have different meanings, and are therefore labelled
# relative to the same gender. So 80kg for male is considered average, but for a
# female 80kg is considered heavy
hist(athletes_data$weight)
hist(athletes_data$weight[athletes_data$sex == 'female'])
hist(athletes_data$weight[athletes_data$sex == 'male'])
summary(athletes_data$weight)
athletes_data$weight = cut(athletes_data$weight, c(30,40,50,60, 70, 80, 90, 100, 110, 120, 130, 140, 170))
table(athletes_data$weight)
table(athletes_data$weight)
# athletes_data$weight[athletes_data$sex == 'female'] = arules::discretize(athletes_data$weight[athletes_data$sex == 'female'], method = "cluster",labels = c('light', 'average_f', 'heavy_f'))
# athletes_data$weight[athletes_data$sex == 'male'] = arules::discretize(athletes_data$weight[athletes_data$sex == 'male'], method = "cluster",labels = c('light', 'average_m', 'heavy_m'))
#
# athletes_data$weight = factor(athletes_data$weight, levels = c(1, 2, 3), labels = c('light', 'average', 'heavy'))
## Podium position (has a medal)
athletes_data$podium = as.integer((athletes_data$gold + athletes_data$silver + athletes_data$bronze) > 0)
### Remove incomplete data rows
athletes_data = na.omit(athletes_data)
removed_rows = length(unique(attributes(athletes_data)$na.action))
attach(athletes_data)
barplot(table(height))
barplot(table(sport))
barplot(table(nationality))
barplot(table(height[podium == 1]))
barplot(table(height[podium == 0]))
barplot(table(height[podium == 1]))
barplot(table(height[podium == 1 & sport == 'basketball']))
barplot(table(height[podium == 0 & sport == 'basketball']))
barplot(table(height[podium == 1 & sport == 'basketball']))
table(sport)
